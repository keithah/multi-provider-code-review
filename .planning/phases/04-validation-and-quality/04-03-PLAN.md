---
phase: 04-validation-and-quality
plan: 03
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/validation/confidence-calculator.ts
  - __tests__/validation/confidence-calculator.test.ts
autonomous: true

must_haves:
  truths:
    - "LLM-reported confidence is used when available"
    - "Validation signals boost confidence when syntax valid"
    - "Consensus boosts confidence when multiple providers agree"
    - "Confidence is capped at 1.0"
  artifacts:
    - path: "src/validation/confidence-calculator.ts"
      provides: "calculateConfidence function"
      exports: ["calculateConfidence", "ConfidenceSignals", "shouldPostSuggestion"]
    - path: "__tests__/validation/confidence-calculator.test.ts"
      provides: "Confidence calculator tests"
      contains: "describe.*confidence"
  key_links:
    - from: "src/validation/confidence-calculator.ts"
      to: "config threshold"
      via: "threshold comparison"
      pattern: "min_confidence|confidence_threshold"
---

<objective>
TDD implementation of hybrid confidence scoring combining LLM confidence with validation signals.

Purpose: Calculate overall confidence for suggestions using multiple signals (LLM confidence, syntax validity, consensus, provider reliability). Confidence determines whether suggestions meet quality thresholds. Per CONTEXT.md, default threshold is 0.7 with per-severity overrides.

Output: Working `calculateConfidence` and `shouldPostSuggestion` functions with comprehensive test coverage.
</objective>

<execution_context>
@/Users/keith/.claude/get-shit-done/workflows/execute-plan.md
@/Users/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-validation-and-quality/04-CONTEXT.md
@.planning/phases/04-validation-and-quality/04-RESEARCH.md
</context>

<feature>
  <name>Confidence Calculator</name>
  <files>src/validation/confidence-calculator.ts, __tests__/validation/confidence-calculator.test.ts</files>
  <behavior>
    calculateConfidence(signals: ConfidenceSignals) -> number

    Cases:
    - LLM confidence only: { llmConfidence: 0.8, syntaxValid: true, hasConsensus: false, providerReliability: 1.0 }
      -> 0.8 * 1.1 (syntax boost) = 0.88
    - LLM + consensus: { llmConfidence: 0.8, syntaxValid: true, hasConsensus: true, providerReliability: 1.0 }
      -> 0.8 * 1.1 * 1.2 = 1.0 (capped)
    - No LLM (fallback): { syntaxValid: true, hasConsensus: false, providerReliability: 0.9 }
      -> (0.5 + 0.2) * 0.9 = 0.63
    - Invalid syntax: { llmConfidence: 0.9, syntaxValid: false, hasConsensus: false, providerReliability: 1.0 }
      -> 0.9 * 0.9 (penalty) = 0.81 (reduced due to syntax failure)

    shouldPostSuggestion(finding, confidence, config) -> boolean

    Cases:
    - Above threshold: confidence=0.8, severity='major', config={min_confidence: 0.7} -> true
    - Below threshold: confidence=0.5, severity='major', config={min_confidence: 0.7} -> false
    - Per-severity: confidence=0.75, severity='critical', config={confidence_threshold:{critical:0.8}} -> false
    - Consensus required: severity='critical', config={consensus.required_for_critical:true}, no consensus -> false
  </behavior>
  <implementation>
    Interface:
    ```typescript
    interface ConfidenceSignals {
      llmConfidence?: number;        // 0-1, from provider response
      syntaxValid: boolean;          // From syntax validator
      hasConsensus: boolean;         // 2+ providers agree
      providerReliability: number;   // 0-1, historical accuracy
    }

    interface QualityConfig {
      min_confidence?: number;       // Default 0.7
      confidence_threshold?: {       // Per-severity overrides
        critical?: number;
        high?: number;
        medium?: number;
        low?: number;
      };
      consensus?: {
        required_for_critical: boolean;
        min_agreement: number;       // Default 2
      };
    }

    function calculateConfidence(signals: ConfidenceSignals): number
    function shouldPostSuggestion(
      finding: { severity: Severity; providers?: string[] },
      confidence: number,
      config: QualityConfig
    ): boolean
    ```

    Confidence formula:
    - If LLM confidence available:
      - Start with llmConfidence
      - Multiply by 1.1 if syntaxValid (max 1.0)
      - Multiply by 1.2 if hasConsensus (max 1.0)
      - Multiply by 0.9 if !syntaxValid (penalty)
      - Multiply by providerReliability
    - Fallback (no LLM confidence):
      - Base: 0.5
      - +0.2 if syntaxValid
      - +0.2 if hasConsensus
      - Multiply by providerReliability

    Threshold logic:
    - Get severity-specific threshold or fall back to min_confidence (default 0.7)
    - Check consensus requirement for critical severity
    - Return confidence >= threshold AND (no consensus req OR has consensus)
  </implementation>
</feature>

<verification>
```bash
npm test -- --testPathPattern="confidence-calculator" --verbose
```
All tests pass. Coverage includes:
- LLM confidence with boosts
- Fallback scoring without LLM
- Syntax penalty
- Threshold comparisons
- Per-severity thresholds
- Consensus requirements
</verification>

<success_criteria>
- RED: Tests fail because calculateConfidence doesn't exist
- GREEN: Tests pass with formula implementation
- REFACTOR: Extract constants, add JSDoc
- Confidence always between 0 and 1
- shouldPostSuggestion respects per-severity thresholds
- Consensus requirement enforced for critical severity
</success_criteria>

<output>
After completion, create `.planning/phases/04-validation-and-quality/04-03-SUMMARY.md`
</output>
