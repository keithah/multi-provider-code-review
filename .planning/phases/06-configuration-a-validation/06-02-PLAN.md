---
phase: 06-configuration-a-validation
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/config/validators.ts
  - src/config/validators.test.ts
autonomous: true

must_haves:
  truths:
    - "clampPercentage clamps values outside 0-100 and logs warning"
    - "validateSeverityWithSuggestion provides typo suggestions for invalid severities"
    - "Levenshtein distance correctly identifies similar strings"
  artifacts:
    - path: "src/config/validators.ts"
      provides: "Validation helper functions for intensity config"
      exports: ["clampPercentage", "validateSeverityWithSuggestion", "levenshteinDistance"]
    - path: "src/config/validators.test.ts"
      provides: "Test coverage for validation helpers"
      contains: "describe.*validators"
  key_links:
    - from: "src/config/validators.ts"
      to: "src/utils/logger"
      via: "logger.warn for clamping warnings"
      pattern: "logger\\.warn"
    - from: "src/config/validators.ts"
      to: "src/utils/validation"
      via: "ValidationError for strict failures"
      pattern: "ValidationError"
---

<objective>
Create validation helpers for intensity configuration with TDD approach.

Purpose: Per CONTEXT.md decisions, consensus percentages should clamp with warnings (not fail), while severity enums should fail strictly with typo suggestions. This plan implements these validation helpers using TDD to ensure correct behavior.

Output: src/config/validators.ts with tested validation functions.
</objective>

<execution_context>
@/Users/keith/.claude/get-shit-done/workflows/execute-plan.md
@/Users/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/06-configuration-a-validation/06-CONTEXT.md
@.planning/phases/06-configuration-a-validation/06-RESEARCH.md

@src/utils/validation.ts
@src/utils/logger.ts
</context>

<feature>
  <name>Intensity Config Validation Helpers</name>
  <files>src/config/validators.ts, src/config/validators.test.ts</files>
  <behavior>
Expected behavior in testable terms:

**clampPercentage(value: number, fieldName: string): number**
- Input: 50, "consensusThreshold" -> Output: 50 (no warning)
- Input: -10, "consensusThreshold" -> Output: 0 (logs warning about clamping)
- Input: 150, "consensusThreshold" -> Output: 100 (logs warning about clamping)
- Input: NaN, "consensusThreshold" -> Output: 50 (logs warning about invalid value)

**validateSeverityWithSuggestion(value: string, field: string): Severity**
- Input: "major", "minSeverity" -> Output: "major" (valid)
- Input: "critical", "minSeverity" -> Output: "critical" (valid)
- Input: "minor", "minSeverity" -> Output: "minor" (valid)
- Input: "majr", "minSeverity" -> Throws ValidationError with hint: "Did you mean 'major'?"
- Input: "critcal", "minSeverity" -> Throws ValidationError with hint: "Did you mean 'critical'?"
- Input: "xyz", "minSeverity" -> Throws ValidationError with hint: "Valid values: critical, major, minor"

**levenshteinDistance(a: string, b: string): number**
- Input: "major", "major" -> Output: 0
- Input: "major", "majr" -> Output: 1
- Input: "critical", "critcal" -> Output: 1
- Input: "abc", "xyz" -> Output: 3
  </behavior>
  <implementation>
TDD cycle:

RED: Write failing tests for all three functions
GREEN: Implement functions to pass tests
REFACTOR: Clean up if needed

Implementation notes from RESEARCH.md:
- Levenshtein: ~15 lines, no external dependency
- Only suggest if distance <= 2 (prevents bad suggestions)
- Use existing ValidationError from src/utils/validation.ts
- Use logger from src/utils/logger.ts for warnings
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>RED: Write Failing Tests</name>
  <files>src/config/validators.test.ts</files>
  <action>
Create test file with comprehensive tests for all three functions:

```typescript
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { clampPercentage, validateSeverityWithSuggestion, levenshteinDistance } from './validators';
import { ValidationError } from '../utils/validation';
import { logger } from '../utils/logger';

// Mock logger
vi.mock('../utils/logger', () => ({
  logger: {
    warn: vi.fn(),
  },
}));

describe('validators', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('levenshteinDistance', () => {
    it('returns 0 for identical strings', () => {
      expect(levenshteinDistance('major', 'major')).toBe(0);
    });

    it('returns 1 for single character difference', () => {
      expect(levenshteinDistance('major', 'majr')).toBe(1);
    });

    it('returns 1 for transposition-like typo', () => {
      expect(levenshteinDistance('critical', 'critcal')).toBe(1);
    });

    it('returns correct distance for completely different strings', () => {
      expect(levenshteinDistance('abc', 'xyz')).toBe(3);
    });

    it('handles empty strings', () => {
      expect(levenshteinDistance('', 'abc')).toBe(3);
      expect(levenshteinDistance('abc', '')).toBe(3);
      expect(levenshteinDistance('', '')).toBe(0);
    });
  });

  describe('clampPercentage', () => {
    it('returns valid values unchanged without warning', () => {
      expect(clampPercentage(50, 'test')).toBe(50);
      expect(clampPercentage(0, 'test')).toBe(0);
      expect(clampPercentage(100, 'test')).toBe(100);
      expect(logger.warn).not.toHaveBeenCalled();
    });

    it('clamps negative values to 0 with warning', () => {
      expect(clampPercentage(-10, 'consensus')).toBe(0);
      expect(logger.warn).toHaveBeenCalledWith(
        expect.stringContaining('consensus')
      );
      expect(logger.warn).toHaveBeenCalledWith(
        expect.stringContaining('-10')
      );
    });

    it('clamps values over 100 to 100 with warning', () => {
      expect(clampPercentage(150, 'threshold')).toBe(100);
      expect(logger.warn).toHaveBeenCalledWith(
        expect.stringContaining('150')
      );
    });

    it('handles NaN with warning and returns 50', () => {
      expect(clampPercentage(NaN, 'test')).toBe(50);
      expect(logger.warn).toHaveBeenCalledWith(
        expect.stringContaining('invalid')
      );
    });

    it('handles Infinity with warning', () => {
      expect(clampPercentage(Infinity, 'test')).toBe(100);
      expect(logger.warn).toHaveBeenCalled();
    });
  });

  describe('validateSeverityWithSuggestion', () => {
    it('returns valid severity values unchanged', () => {
      expect(validateSeverityWithSuggestion('critical', 'field')).toBe('critical');
      expect(validateSeverityWithSuggestion('major', 'field')).toBe('major');
      expect(validateSeverityWithSuggestion('minor', 'field')).toBe('minor');
    });

    it('is case-insensitive', () => {
      expect(validateSeverityWithSuggestion('MAJOR', 'field')).toBe('major');
      expect(validateSeverityWithSuggestion('Critical', 'field')).toBe('critical');
    });

    it('throws ValidationError with typo suggestion for close matches', () => {
      expect(() => validateSeverityWithSuggestion('majr', 'minSeverity'))
        .toThrow(ValidationError);

      try {
        validateSeverityWithSuggestion('majr', 'minSeverity');
      } catch (e) {
        expect(e).toBeInstanceOf(ValidationError);
        expect((e as ValidationError).hint).toContain('major');
      }
    });

    it('throws ValidationError with typo suggestion for critcal', () => {
      try {
        validateSeverityWithSuggestion('critcal', 'field');
      } catch (e) {
        expect((e as ValidationError).hint).toContain('critical');
      }
    });

    it('throws ValidationError with valid values list for distant strings', () => {
      try {
        validateSeverityWithSuggestion('xyz', 'field');
      } catch (e) {
        expect((e as ValidationError).hint).toContain('Valid values:');
        expect((e as ValidationError).hint).toContain('critical');
        expect((e as ValidationError).hint).toContain('major');
        expect((e as ValidationError).hint).toContain('minor');
      }
    });

    it('throws for non-string input', () => {
      expect(() => validateSeverityWithSuggestion(123 as unknown as string, 'field'))
        .toThrow(ValidationError);
    });
  });
});
```

Run `npm test src/config/validators.test.ts` - tests should fail (module not found).
  </action>
  <verify>Run `npm test src/config/validators.test.ts` - tests fail with "Cannot find module './validators'"</verify>
  <done>Test file exists with comprehensive test cases that fail</done>
</task>

<task type="auto">
  <name>GREEN: Implement Validators to Pass Tests</name>
  <files>src/config/validators.ts</files>
  <action>
Create validators.ts with implementations:

```typescript
/**
 * Configuration validation helpers for intensity behavior fields.
 *
 * Per CONTEXT.md decisions:
 * - Consensus percentages: clamp to 0-100 with warning (continue running)
 * - Severity enums: strict validation with typo suggestions (fail fast)
 */

import { Severity } from '../types';
import { ValidationError } from '../utils/validation';
import { logger } from '../utils/logger';

const SEVERITY_VALUES = ['critical', 'major', 'minor'] as const;

/**
 * Calculate Levenshtein edit distance between two strings.
 * Used for typo detection in enum validation.
 */
export function levenshteinDistance(a: string, b: string): number {
  const matrix: number[][] = [];

  // Initialize first column
  for (let i = 0; i <= a.length; i++) {
    matrix[i] = [i];
  }

  // Initialize first row
  for (let j = 0; j <= b.length; j++) {
    matrix[0][j] = j;
  }

  // Fill matrix
  for (let i = 1; i <= a.length; i++) {
    for (let j = 1; j <= b.length; j++) {
      const cost = a[i - 1] === b[j - 1] ? 0 : 1;
      matrix[i][j] = Math.min(
        matrix[i - 1][j] + 1,      // deletion
        matrix[i][j - 1] + 1,      // insertion
        matrix[i - 1][j - 1] + cost // substitution
      );
    }
  }

  return matrix[a.length][b.length];
}

/**
 * Find closest matching string from candidates.
 * Only returns match if distance <= 2 to avoid bad suggestions.
 */
function findClosestMatch(input: string, candidates: readonly string[]): string | null {
  const normalized = input.toLowerCase();
  let closest: string | null = null;
  let minDistance = Infinity;

  for (const candidate of candidates) {
    const distance = levenshteinDistance(normalized, candidate);
    if (distance < minDistance && distance <= 2) {
      minDistance = distance;
      closest = candidate;
    }
  }

  return closest;
}

/**
 * Clamp percentage to valid 0-100 range, logging warning if adjusted.
 * Per CONTEXT.md: clamp with warning, don't fail.
 */
export function clampPercentage(value: number, fieldName: string): number {
  if (!Number.isFinite(value)) {
    logger.warn(`${fieldName}: invalid value ${value}, using 50`);
    return 50;
  }

  if (value < 0) {
    logger.warn(`${fieldName}: ${value} clamped to 0 (valid range: 0-100)`);
    return 0;
  }

  if (value > 100) {
    logger.warn(`${fieldName}: ${value} clamped to 100 (valid range: 0-100)`);
    return 100;
  }

  return value;
}

/**
 * Validate severity enum with typo suggestions.
 * Per CONTEXT.md: strict validation, fail with helpful message.
 */
export function validateSeverityWithSuggestion(
  value: unknown,
  field: string
): Severity {
  if (typeof value !== 'string') {
    throw new ValidationError(
      `${field} must be a string`,
      field,
      `Received type: ${typeof value}`
    );
  }

  const normalized = value.toLowerCase();

  if (SEVERITY_VALUES.includes(normalized as Severity)) {
    return normalized as Severity;
  }

  // Find closest match for typo suggestion
  const suggestion = findClosestMatch(normalized, SEVERITY_VALUES);

  throw new ValidationError(
    `${field} has invalid value: "${value}"`,
    field,
    suggestion
      ? `Did you mean '${suggestion}'?`
      : `Valid values: ${SEVERITY_VALUES.join(', ')}`
  );
}
```

Run tests to verify all pass.
  </action>
  <verify>Run `npm test src/config/validators.test.ts` - all tests pass</verify>
  <done>All validation helper functions implemented and tests passing</done>
</task>

<task type="auto">
  <name>REFACTOR: Review and Clean Up</name>
  <files>src/config/validators.ts</files>
  <action>
Review implementation for any obvious improvements:

1. Check for duplicate code that could be extracted
2. Verify error messages are consistent with existing codebase style
3. Ensure JSDoc comments are complete
4. Verify exports are properly organized

If no changes needed, this is a no-op task. Run tests to confirm no regressions.

Add any edge cases discovered during implementation to tests if needed.
  </action>
  <verify>Run `npm test src/config/validators.test.ts` - all tests still pass. Run `npm run build` - compiles without errors.</verify>
  <done>Validators are clean, well-documented, and fully tested</done>
</task>

</tasks>

<verification>
After all tasks:
1. `npm test src/config/validators.test.ts` passes
2. `npm run build` succeeds
3. Coverage for validators.ts is high (all branches covered)
</verification>

<success_criteria>
- [ ] levenshteinDistance correctly calculates edit distance
- [ ] clampPercentage clamps to 0-100 and logs warnings
- [ ] validateSeverityWithSuggestion provides typo suggestions for close matches
- [ ] validateSeverityWithSuggestion fails strictly for invalid values
- [ ] All tests pass
- [ ] Build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/06-configuration-a-validation/06-02-SUMMARY.md`
</output>
